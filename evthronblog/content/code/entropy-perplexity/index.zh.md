---
title: "熵和困惑度"
description: 
date: 2025-05-19T10:41:21+08:00
lastmod: 2025-05-19T10:41:21+08:00
image: 
categories: 
tags: 
math: true
license: 
hidden: false
comments: true
---

## 熵
雖然我的數學不差，但我只要看見對數就不爽。不僅意義很難懂，而且往往只是因為「這個公式是指數函數，用起來很不方便，所以我們就加個 log 把它壓平，變成線性函數」，就拿來用了，沒有什麼深層次的原因。

熵，Entropy，這個聽起來很帥的科幻術語，也因為相同的原因，有着一條考試時背不出來的古怪公式。

$$
H(P) = -\sum_{i=1}^n p(i) \log(p(i))
$$

「概率乘以概率的對數」，公式看起來很簡單所以沒理由記不住，但真要解釋是什麼意思就説不上來了。第一步是要糾正數學家喜歡簡化公式的壞毛病，用稍嫌累贅的方法重新寫一次公式吧。

$$
H(P) = \sum_{i=1}^n p(i) \log(\frac{1}{p(i)})
$$

第一種理解熵的方法，是「取對數後的平均稀有度」。

概率越高，越有可能發生，事情就越不稀有。所以可以用 $p$ 的倒數 $\frac{1}{p}$ 代表稀有度。

把所有事件的稀有度取 log ，按照發生的頻率做按比例加起來，也就是乘以概率，就得到了總體事件的稀有度。

拋硬幣得到每種結果的概率都是一樣的，所以每一種事件的稀有度也是相同的。

$\frac{1}{\frac{1}{2} = 2$ ，$\log 2 = 1$。拋一次硬幣，無論得到的結果是正面還是反面。稀有度都是 1。所以平均來說，拋一次硬幣這個事件的稀有度也是 1。

每個結果的概率均等的話，似乎看不出稀有度為什麼要取平均，這裏再給一個換個概率不均等的例子。

硬幣得到正面的概率是 1/3，得到反面的結果是 2/3，正面的稀有度是 3，反面的稀有度是 1.5，取 log 之後得到 1.58 和 0.58。所以整個拋硬幣事件的稀有度是 1.58 × 1/3 + 0.58 × 2/3 = 0.913。數值比公平硬幣低，說明比拋不公平的硬幣和公平硬幣相比少了點驚喜。

結果越難預測，稀有度就越高。熵就越高。

***

我們還可以從訊息論的角度理解熵的概念：熵的數值，等於表達每一種結果平均需要的比特數。

一個比特能表示兩種狀態，兩個比特能表示四種。2, 4, 8, 16。每增加一個比特，能表示的狀態數量就會翻一倍。

拋兩次硬幣，會有四種可能的結果，總共的狀態數量是四種。

把這些事件編碼需要的位數，等於 $\log_2(\frac{1}{p})$。在這裡，取 log 不只是為了方便計算，而是為了把狀態數變成比特數。

可能發生的事件的狀態，也就是上面說的稀有度，等於 1/p，時間的數量越多，就越難預測，越難預測的事件就越令人困惑，所以總共有可能的事件數量，也叫做困惑度。

一個比特能表達多少個訊息的，不是固定的。果一個位可以表達兩種狀態，就用 $\log_2$，如果一個位可以表達三種狀態，就用 $\log_3$。如果一個位可以表達$e$種狀態，就用 $\ln$。

但是，困惑度是不會改變的，無論用多少個位表達，結果的數量是不會變的，似乎應該是更加基礎的概念，但我們之所以用熵而不是用困惑度表示資訊量，是因為結果的數量有着麻煩的指數性質，而編碼需要的位數則能漂亮地相加，更容易理解。

## 困惑度

我試着無視課本，脱離熵的定義，直接求困惑度。

接下來要舉的例子可能有點多餘，但對理解接下來的不平均概率分佈有幫助。

拋硬幣有兩種結果，所以拋兩次會有 2 x 2 = 4 種結果。那麼，平均拋一次的結果數是多少呢？是 4 的開平方，也就是回到了一開始的 2。如果拋三次硬幣就會有 2 x 2 x 2 = 8 種結果，平均拋一次的結果數是 8 的 開立方，一樣是 2。

接下來是不平均的概率分佈，我們現在有一個不公平的硬幣，有 1/4 的可能是正面，有 3/4 的可能是反面。現在我們有多少個事件呢？雖然只有兩個結果，但是這個概率分佈的隨機性是比公平的硬幣低的，比起正面，更有可能是反面，所以實際預期的平均事件數，也就是不確定性，應該是比 2 少的。

用剛才的做法，現在我們拋四次這個硬幣，有多少種可能的結果呢？先算正面，事件數是 $1/\frac{1}{4} = 4$，也就是説，每 4 次就會出現一次正面，正面的結果會發生多少次呢？四次裏面會有一次，所以自乘一次，還是 $4$。

反面呢？這次的事件數是 $1/\frac{3}{4} = \frac{4}{3}$，不是整數！意思是，如果一個事件發生的概率是 $\frac{3}{4}$，那我們預期每 $\frac{4}{3}$ 次就會發生一次事件，反面的結果會發生 3 次，所以要計算 $(\frac{4}{3})^3 \approx 2.37$，意思是，如果我把拋 3 次硬幣當作一次實驗，我們可以預期每重複 2.37 次實驗就會出現一次三個反面。

這樣一來，我們就得到了一次正面和三次反面，我們把這個事件叫作「典型事件」。為了得到這個「典型事件」，我們需要等待 $4 \times 2.37 = 9.481$，意思是，一次拋四個硬幣，每 9.481 次就會得到一次「典型事件」。（雖然典型事件有四種排列組合，但只用一個就能算得出來。我不是很清楚為什麼。）

雖然「典型事件」至少需要拋四次才能發生，但抽象地説，如果只拋一次，要多少次才能得到一個「典型事件」呢？答案會是 9.481 的開四次方，也就是 1.754。這就是預期的平均事件數，如果發生的可能事件越多，不確定性就越大，這個事件數就是「困惑度」。拋這個不公平硬幣的不確定性，相當於拋一個只有 1.754 個面的公平硬幣。

按照上面這個可能有漏洞的推論，我們得到了不依賴熵來定義困惑度的公式：

$$
\text{Perplexity} = \sqrt[N]{\prod_{i=1}^n \left(\frac{1}{p_i}\right)^{k_i}}
$$

其中：
- $p_i$ 是事件 $i$ 的概率
- $k_i$ 是事件 $i$ 發生的次數
- $N$ 是總實驗次數

或者用更簡單的寫法：
$$
\text{Perplexity} = \prod_{i=1}^n \left(\frac{1}{p_i}\right)^{p_i}
$$

$$
H(P) = \sum_{i=1}^n p(i) \log(\frac{1}{p(i)})
$$

這和熵的公式只差了一個 log，可以看見真正的資訊量有相乘的性質，很麻煩。這甚至是我第一次看見幾何平均，最大的問題是概率相乘會變得很小，電腦的精度不夠。而編碼資訊需要的比特數則有着相加的性質，更加好用。所以用熵來定義困惑度感覺是一種運算上的技巧。

## 交叉熵
交叉熵能對比兩個概率分佈的相似度。
$$
CE(P, Q) = \sum_{i=1}^n \text{actualProbability}(i) \log(\frac{1}{\text{predictionProbability}(i)})
$$

交叉熵同樣是熵，所以意義也是編碼需要的比特量。一般的熵代表的是編碼需要的最小比特數，而交叉熵就説明了當我們的概率預測出錯的時候，實際需要的比特數。要讓編碼的比特數變得最少，就要給發生概率高的事件分配短一點的編碼，給發生概率低的事件用長一點的編碼也沒關係，如果對於一件發生概率很高的事件，我們卻以為發生概率很低，$\log(\frac{1}{p(i)})$ 就會變大，會分配多了好幾個比特用來編碼，訊息就會變得很冗長。因此降低交叉熵就能讓預測的概率接近正確的概率。

